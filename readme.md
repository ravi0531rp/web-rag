# WEB RAG

## Introduction
* Given a web page's address, our application will try to parse data in that page as well as all the
links available in the page recursively. 
* And then, based off of that data, we will use our LLM based backend to answer queries.
* Hosted [Website](https://ravi0531rp.github.io/web-rag/) using Github IO.

## Elements

-  Create a docs website
-  Create the web scraper
-  Vector Store
-  LLM Backend
-  Query FrontEnd


## KEY MILESTONES
- [ ] Create a simple website with some links to other pages ; web scraper ; LLM Backend
- [ ] Now add more data like Tables, Images and links to external webpages & handle that.
- [ ] Deploy on Cloud (Preferably AWS)